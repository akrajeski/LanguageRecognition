{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is part 2/2 for the notebooks.**\n",
    "\n",
    "This section is for the complete code that will be used in the final product. For additional information, please visit 1_data_training.ipynb\n",
    "\n",
    "This model was derived from all exploration of EDA and models, along with testing different approaches (including BoW, linear regression, and Naive Bayes). The approach of Linear Regression was deemed best, and used in the following code. TF-IDF (Term Frequency-Inverse Document Frequency) was also used to figure out how many times a word was used within a document, and weighted appropriately. This assisted with making a higher accuracy rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 1323 files extracted and written to CEFRRaw.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "# These texts in the CEFRTexts folder are supplemented with additional texts.\n",
    "def extract_metadata(text):\n",
    "    # Define patterns for each metadata field. This is altered after the original attempt.\n",
    "    patterns = {\n",
    "        \"Overall CEFR rating\": r\"Overall CEFR rating: (.+)\",\n",
    "        \"Learner text\": r\"(?i)Learner text:\\s+([\\s\\S]+?)$\"  # Match all text after \"Learner text:\"\n",
    "    }\n",
    "    \n",
    "    extracted_data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, text, re.MULTILINE)\n",
    "        extracted_data[key] = match.group(1).strip() if match else \"\"\n",
    "    return extracted_data\n",
    "\n",
    "def process_folder(input_folder, output_file):\n",
    "    # List all .txt files in the folder\n",
    "    files = [f for f in os.listdir(input_folder) if f.endswith('.txt')]\n",
    "    if not files:\n",
    "        print(\"No .txt files found in the specified folder.\")\n",
    "        return\n",
    "\n",
    "    # Process each file and collect data\n",
    "    all_data = []\n",
    "    for file in files:\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        metadata = extract_metadata(text)\n",
    "        metadata['Filename'] = file  # Add filename for reference\n",
    "        all_data.append(metadata)\n",
    "    \n",
    "    # Write all data to a single CSV\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = list(all_data[0].keys())  # Use keys from the first entry\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_data)\n",
    "\n",
    "    print(f\"Data from {len(files)} files extracted and written to {output_file}\")\n",
    "\n",
    "def main():\n",
    "    input_folder = \"CEFRTexts\"  # Containing .txt files\n",
    "    output_file = \"CEFRRaw.csv\"     # Desired output CSV file\n",
    "\n",
    "    process_folder(input_folder, output_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Overall CEFR rating\n",
       "A1    207\n",
       "A2    306\n",
       "B1    331\n",
       "B2    293\n",
       "C1     82\n",
       "C2    104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('CEFRRaw.csv')\n",
    "df.head()\n",
    "\n",
    "df.groupby('Overall CEFR rating').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall CEFR rating    0\n",
      "Learner text           0\n",
      "Filename               0\n",
      "cleaned_text           0\n",
      "dtype: int64\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the entire dataframe\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Focus on the 'Learner text' column\n",
    "print(df['Learner text'].isnull().sum())\n",
    "print(df['Overall CEFR rating'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty text rows:\n",
      "Empty DataFrame\n",
      "Columns: [Overall CEFR rating, Learner text, Filename]\n",
      "Index: []\n",
      "Short text rows:\n",
      "Empty DataFrame\n",
      "Columns: [Overall CEFR rating, Learner text, Filename]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for empty or whitespace-only strings\n",
    "empty_text = df[df['Learner text'].str.strip() == '']\n",
    "print(\"Empty text rows:\")\n",
    "print(empty_text)\n",
    "\n",
    "# Check for unusually short strings (e.g., less than 3 characters)\n",
    "short_text = df[df['Learner text'].str.len() < 3]\n",
    "print(\"Short text rows:\")\n",
    "print(short_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the file with a specific encoding\n",
    "df = pd.read_csv('CEFRRaw.csv', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is now checked. It will now be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Learner text  \\\n",
      "0  Das ist ein Beispiel für einen C1-Satz, der ei...   \n",
      "1  Ich begrüße alle, der sich für das Thema „Länd...   \n",
      "2  Sehr geehrt Frau Schmidt, ich bin ein paar Tag...   \n",
      "3                                        Liebe Julia   \n",
      "4  Meine Meinung nach ist sinnlos, auch in Auslan...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  Csatz spezifisch Thema behandeln Csatz spezifi...  \n",
      "1  begrüßen Thema Land Tradition interessieren Me...  \n",
      "2                      ehren Frau Schmidt paar Hause  \n",
      "3                                        Liebe Julia  \n",
      "4  Meinung sinnlos Ausland Tradition heimatland f...  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load German model\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "# Load DataFrame\n",
    "df = pd.read_csv('CEFRRaw.csv')\n",
    "\n",
    "# Function for text cleaning\n",
    "def clean_text(text, apply_stemming=False, apply_lemmatization=True):\n",
    "    if not isinstance(text, str):\n",
    "        return text \n",
    "\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters, numbers, and extra spaces\n",
    "    text = re.sub(r'[^a-zäöüß\\s]', '', text)  # Retain only letters and German-specific characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "\n",
    "    # Process the text using SpaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Tokenize, remove stopwords, and optionally lemmatize -- these come within SpaCy\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop:  # Remove stopwords\n",
    "            if apply_lemmatization:\n",
    "                tokens.append(token.lemma_)  # Use lemmatized form\n",
    "            else:\n",
    "                tokens.append(token.text)  # Use raw token text\n",
    "\n",
    "    # Join tokens back into a single string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Add a new column for cleaned text\n",
    "df['cleaned_text'] = df['Learner text'].apply(lambda x: clean_text(x, apply_stemming=False, apply_lemmatization=True))\n",
    "\n",
    "# Preview the original and cleaned text\n",
    "print(df[['Learner text', 'cleaned_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Shape: (1323, 5000)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF (Term Frequency-Inverse Document Frequency) will be used for this model. This was explored in the previous notebook.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "# ** This code was generated using ChatGPT ** \n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit to 5000 most important features\n",
    "    ngram_range=(1, 2),  # Include unigrams and bigrams\n",
    "    stop_words=None      # Stopword removal already handled in preprocessing\n",
    ")\n",
    "\n",
    "# Transform cleaned text to TF-IDF representation\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# Check the shape of the resulting TF-IDF matrix\n",
    "print(f\"TF-IDF Shape: {X_tfidf.shape}\")  # Rows: samples, Columns: features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (1058, 5000), Test Shape: (265, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['Overall CEFR rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train Shape: {X_train.shape}, Test Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6377358490566037\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.93      0.70      0.80        37\n",
      "          A2       0.57      0.44      0.50        54\n",
      "          B1       0.53      0.55      0.54        71\n",
      "          B2       0.56      0.82      0.67        61\n",
      "          C1       0.75      0.45      0.56        20\n",
      "          C2       1.00      0.95      0.98        22\n",
      "\n",
      "    accuracy                           0.64       265\n",
      "   macro avg       0.72      0.65      0.67       265\n",
      "weighted avg       0.66      0.64      0.64       265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Attempting Logistic Regression with this!\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorizer saved as tfidf_vectorizer.pkl\n",
      "Logistic Regression model saved as logistic_regression_model.pkl\n",
      "Logistic Regression Accuracy: 0.6377358490566037\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.93      0.70      0.80        37\n",
      "          A2       0.57      0.44      0.50        54\n",
      "          B1       0.53      0.55      0.54        71\n",
      "          B2       0.56      0.82      0.67        61\n",
      "          C1       0.75      0.45      0.56        20\n",
      "          C2       1.00      0.95      0.98        22\n",
      "\n",
      "    accuracy                           0.64       265\n",
      "   macro avg       0.72      0.65      0.67       265\n",
      "weighted avg       0.66      0.64      0.64       265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Saving the pretrained model so it can be accessed for streamlit_app.py\n",
    "# PLEASE NOTE: if adjusting input data this entire notebook will need to be run again!\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit to 5000 most important features\n",
    "    ngram_range=(1, 2),  # Include unigrams and bigrams\n",
    "    stop_words=None      # Stopword removal already handled in preprocessing\n",
    ")\n",
    "\n",
    "# Transform cleaned text to TF-IDF representation\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# Save the trained TF-IDF vectorizer\n",
    "joblib.dump(tfidf_vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "print(\"TF-IDF vectorizer saved as tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['Overall CEFR rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained logistic regression model\n",
    "joblib.dump(log_reg, \"logistic_regression_model.pkl\")\n",
    "print(\"Logistic Regression model saved as logistic_regression_model.pkl\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
